{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5771ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56481b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_seq(A, target):\n",
    "    \"\"\" input list of elements, and target element, return longest sequence of target \"\"\"\n",
    "    cnt, max_val = 0, 0 # running count, and max count\n",
    "    for e in A: \n",
    "        cnt = cnt + 1 if e == target else 0  # add to or reset running count\n",
    "        max_val = max(cnt, max_val) # update max count\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d979257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dee8d62c5d41efa3b49d570787e1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"prediction\")\n",
    "files = [x for x in files if x.endswith(\"HE.tsv\")]\n",
    "\n",
    "def binar(x):\n",
    "    \n",
    "    if x != 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def to_sequence(seq):\n",
    "    \n",
    "    resolution = 20\n",
    "    chunks = np.array_split(seq,resolution)\n",
    "    info = [np.mean(x) for x in chunks]\n",
    "    \n",
    "    return info\n",
    "\n",
    "result = []\n",
    "    \n",
    "for fname in tqdm(files):\n",
    "    \n",
    "    data = pd.read_csv(\"prediction/\"+fname, sep=\"\\t\")\n",
    "    label = data.iloc[:,-2:].apply(lambda x: softmax(x)[1], axis=1)\n",
    "    try:\n",
    "        \n",
    "        HE = max(label[label > 0.5].index)\n",
    "        \n",
    "        seq = np.zeros(len(label))\n",
    "        seq[HE] = 1\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        seq = np.zeros(len(label))\n",
    "        \n",
    "    seq = to_sequence(seq)\n",
    "    seq = [binar(x) for x in seq]\n",
    "    result.append([fname, seq])\n",
    "    \n",
    "heres = pd.DataFrame(result)\n",
    "heres.columns = [\"fname\", \"HE_series\"]\n",
    "heres.index = [re.sub(\"\\§.*\",\"\",x) for x in heres.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a71af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a11001a84944168631ca7013800638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"prediction\")\n",
    "files = [x for x in files if x.endswith(\"CO.tsv\")]\n",
    "\n",
    "def binar(x):\n",
    "    \n",
    "    if x != 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def to_sequence(seq):\n",
    "    \n",
    "    resolution = 20\n",
    "    chunks = np.array_split(seq,resolution)\n",
    "    info = [np.mean(x) for x in chunks]\n",
    "    \n",
    "    return info\n",
    "\n",
    "result = []\n",
    "    \n",
    "for fname in tqdm(files):\n",
    "    \n",
    "    data = pd.read_csv(\"prediction/\"+fname, sep=\"\\t\")\n",
    "    label = data.iloc[:,-2:].apply(lambda x: softmax(x)[1], axis=1)\n",
    "    try:\n",
    "        \n",
    "        CO = label.sort_values().index[-1]\n",
    "        \n",
    "        seq = np.zeros(len(label))\n",
    "        seq[CO] = 1\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        seq = np.zeros(len(label))\n",
    "        \n",
    "    seq = to_sequence(seq)\n",
    "    seq = [binar(x) for x in seq]\n",
    "    result.append([fname, seq])\n",
    "    \n",
    "cores = pd.DataFrame(result)\n",
    "cores.columns = [\"fname\", \"CO_series\"]\n",
    "cores.index = [re.sub(\"\\§.*\",\"\",x) for x in cores.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec936b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87bcd72a87746f2a7064ee31d103215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret / rcount\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret / rcount\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret / rcount\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret / rcount\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret / rcount\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/konle/anaconda3/envs/gpu/lib/python3.9/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret / rcount\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"prediction\")\n",
    "files = [x for x in files if x.endswith(\"ME.tsv\")]\n",
    "\n",
    "def binar(x):\n",
    "    \n",
    "    if x != 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_labels(x):\n",
    "\n",
    "  \n",
    "    x = softmax(x)\n",
    "    \n",
    "    if np.argmax(x) == 0 and max(x) > 0.9:\n",
    "        \n",
    "        return np.array(0)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return np.array(1)\n",
    "    \n",
    "\n",
    "def to_sequence(seq):\n",
    "    \n",
    "    resolution = 20\n",
    "    chunks = np.array_split(seq,resolution)\n",
    "    info = [np.mean(x) for x in chunks]\n",
    "    \n",
    "    return info\n",
    "\n",
    "result = []\n",
    "    \n",
    "for fname in tqdm(files):\n",
    "    \n",
    "    data = pd.read_csv(\"prediction/\"+fname, sep=\"\\t\")\n",
    "    label = data.iloc[:,-2:].apply(lambda x: get_labels(x), axis=1)\n",
    "    seq = to_sequence(np.array(label))\n",
    "    long = longest_seq(np.array(label), 0)\n",
    "    \n",
    "    result.append([fname, seq, long])\n",
    "    \n",
    "meres = pd.DataFrame(result)\n",
    "meres.columns = [\"fname\", \"ME_series\",\"ME_long\"]\n",
    "meres.index = [re.sub(\"\\§.*\",\"\",x) for x in meres.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184f6b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15393b5f33944f44bae36472b1518c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/993 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = os.listdir(\"prediction\")\n",
    "files = [x for x in files if x.endswith(\"emotions_dataset.tsv\")]\n",
    "\n",
    "def to_sequence(seq):\n",
    "    \n",
    "    resolution = 20\n",
    "    chunks = np.array_split(seq,resolution)\n",
    "    info = [np.mean(x) for x in chunks]\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def get_labels(x):\n",
    "\n",
    "    if sum(x) < 0.95 or sum(x) > 1.1:\n",
    "        x = softmax(x)\n",
    "    \n",
    "    if np.argmax(x) == 0 or max(x) < 0.95:\n",
    "        \n",
    "        return np.array([0,0])\n",
    "    \n",
    "    if np.argmax(x) == 1:\n",
    "        \n",
    "        return np.array([1,0])\n",
    "    \n",
    "    if np.argmax(x) == 2:\n",
    "        \n",
    "        return np.array([0,1])\n",
    "\n",
    "result = []\n",
    "    \n",
    "for fname in tqdm(files):\n",
    "    \n",
    "    data = pd.read_csv(\"prediction/\"+fname, sep=\"\\t\")\n",
    "    label = data.iloc[:,-3:].apply(lambda x: get_labels(x), axis=1)\n",
    "    label = np.stack(list(label))\n",
    "    add = pd.DataFrame(label)\n",
    "    add.columns = [\"Emotion_pos\",\"Emotion_neg\"]\n",
    "    data = pd.concat([data, add], axis=1)\n",
    "    \n",
    "    \n",
    "    gp = data.groupby(\"Scene\").sum(\"Emotion_pos\")\n",
    "    \n",
    "    result.append([fname, data[\"Emotion_pos\"].mean(), data[\"Emotion_neg\"].mean(), \n",
    "                   to_sequence(gp[\"Emotion_pos\"]), to_sequence(gp[\"Emotion_neg\"])])\n",
    "    \n",
    "    \n",
    "emores = pd.DataFrame(result)\n",
    "emores.columns = [\"fname\",\"Emotion_pos_mean\",\"Emotion_neg_mean\", \"Emotion_pos_series\", \"Emotion_neg_series\"]\n",
    "emores.index = [re.sub(\"\\§.*\",\"\",x) for x in emores.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc46d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471473ec3eb54525ae973130104abe82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/990 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = os.listdir(\"prediction\")\n",
    "files = [x for x in files if x.endswith(\"character_dataset.tsv\")]\n",
    "\n",
    "\n",
    "def to_sequence(seq):\n",
    "    \n",
    "    resolution = 20\n",
    "    chunks = np.array_split(seq,resolution)\n",
    "    info = [np.mean(x) for x in chunks]\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def get_labels(x):\n",
    "\n",
    "    if sum(x) < 0.95 or sum(x) > 1.1:\n",
    "        x = softmax(x)\n",
    "    \n",
    "    if np.argmax(x) == 0 or max(x) < 0.95:\n",
    "        \n",
    "        return np.array([0,0])\n",
    "    \n",
    "    if np.argmax(x) == 1:\n",
    "        \n",
    "        return np.array([1,0])\n",
    "    \n",
    "    if np.argmax(x) == 2:\n",
    "        \n",
    "        return np.array([0,1])\n",
    "\n",
    "result = []\n",
    "    \n",
    "for fname in tqdm(files):\n",
    "    \n",
    "    data = pd.read_csv(\"prediction/\"+fname, sep=\"\\t\")\n",
    "    label = data.iloc[:,-3:].apply(lambda x: get_labels(x), axis=1)\n",
    "    label = np.stack(list(label))\n",
    "    add = pd.DataFrame(label)\n",
    "    add.columns = [\"Char_pos\",\"Char_neg\"]\n",
    "    data = pd.concat([data, add], axis=1)\n",
    "    \n",
    "    gp = data.groupby(\"Scene\").sum(\"Char_pos\")\n",
    "    \n",
    "    result.append([fname, data[\"Char_pos\"].mean(), data[\"Char_neg\"].mean(), \n",
    "                   to_sequence(gp[\"Char_pos\"]), to_sequence(gp[\"Char_neg\"])])\n",
    "    \n",
    "    \n",
    "charres = pd.DataFrame(result)\n",
    "charres.columns = [\"fname\",\"Char_pos_mean\",\"Char_neg_mean\", \"Char_pos_series\", \"Char_neg_series\"]\n",
    "charres.index = [re.sub(\"\\§.*\",\"\",x) for x in charres.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe6f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927a07ef380141a7806c443aed61ba6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = os.listdir(\"prediction\")\n",
    "files = [x for x in files if x.endswith(\"body_dataset.tsv\")]\n",
    "\n",
    "\n",
    "def to_sequence(seq):\n",
    "    \n",
    "    resolution = 20\n",
    "    chunks = np.array_split(seq,resolution)\n",
    "    info = [np.mean(x) for x in chunks]\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def get_labels(x):\n",
    "\n",
    "    if sum(x) < 0.95 or sum(x) > 1.1:\n",
    "        x = softmax(x)\n",
    "    \n",
    "    if np.argmax(x) == 0 or max(x) < 0.95:\n",
    "        \n",
    "        return np.array([0,0])\n",
    "    \n",
    "    if np.argmax(x) == 1:\n",
    "        \n",
    "        return np.array([1,0])\n",
    "    \n",
    "    if np.argmax(x) == 2:\n",
    "        \n",
    "        return np.array([0,1])\n",
    "\n",
    "result = []\n",
    "    \n",
    "for fname in tqdm(files):\n",
    "    \n",
    "    data = pd.read_csv(\"prediction/\"+fname, sep=\"\\t\")\n",
    "    label = data.iloc[:,-3:].apply(lambda x: get_labels(x), axis=1)\n",
    "    label = np.stack(list(label))\n",
    "    add = pd.DataFrame(label)\n",
    "    add.columns = [\"Body_pos\",\"Body_neg\"]\n",
    "    data = pd.concat([data, add], axis=1)\n",
    "    \n",
    "    gp = data.groupby(\"Scene\").sum(\"Char_pos\")\n",
    "    \n",
    "    result.append([fname, data[\"Body_pos\"].mean(), data[\"Body_neg\"].mean(), \n",
    "                   to_sequence(gp[\"Body_pos\"]), to_sequence(gp[\"Body_neg\"])])\n",
    "    \n",
    "    \n",
    "bodyres = pd.DataFrame(result)\n",
    "bodyres.columns = [\"fname\",\"Body_pos_mean\",\"Body_neg_mean\", \"Body_pos_series\", \"Body_neg_series\"]\n",
    "bodyres.index = [re.sub(\"\\§.*\",\"\",x) for x in bodyres.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93f1e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47146e3036c24dc9a140008da03f96dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = os.listdir(\"prediction\")\n",
    "files = [x for x in files if x.endswith(\"attraction_dataset.tsv\")]\n",
    "\n",
    "\n",
    "def to_sequence(seq):\n",
    "    \n",
    "    resolution = 20\n",
    "    chunks = np.array_split(seq,resolution)\n",
    "    info = [np.mean(x) for x in chunks]\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "def get_labels(x):\n",
    "    \n",
    "    if sum(x) < 0.95 or sum(x) > 1.1:\n",
    "        x = softmax(x)\n",
    "    \n",
    "    if np.argmax(x) == 0 or max(x) < 0.9:\n",
    "        \n",
    "        return np.array([0])\n",
    "    \n",
    "    if np.argmax(x) == 1:\n",
    "        \n",
    "        return np.array([1])\n",
    "    \n",
    "\n",
    "result = []\n",
    "    \n",
    "for fname in tqdm(files):\n",
    "    \n",
    "    data = pd.read_csv(\"prediction/\"+fname, sep=\"\\t\")\n",
    "    label = data.iloc[:,-2:].apply(lambda x: get_labels(x), axis=1)\n",
    "    label = np.stack(list(label))\n",
    "    add = pd.DataFrame(label)\n",
    "    add.columns = [\"Attraction\"]\n",
    "    data = pd.concat([data, add], axis=1)\n",
    "    \n",
    "    gp = data.groupby(\"Scene\").sum(\"Attraction\")\n",
    "    \n",
    "    result.append([fname, data[\"Attraction\"].mean(),  to_sequence(gp[\"Attraction\"])])\n",
    "    \n",
    "    \n",
    "attres = pd.DataFrame(result)\n",
    "attres.columns = [\"fname\",\"Attraction_mean\", \"Attraction_series\"]\n",
    "attres.index = [re.sub(\"\\§.*\",\"\",x) for x in attres.fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881d5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690b57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe = pd.concat([emores, charres, bodyres, attres, meres, heres, cores], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcce7a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Emotion_pos_mean</th>\n",
       "      <th>Emotion_neg_mean</th>\n",
       "      <th>Emotion_pos_series</th>\n",
       "      <th>Emotion_neg_series</th>\n",
       "      <th>fname</th>\n",
       "      <th>Char_pos_mean</th>\n",
       "      <th>Char_neg_mean</th>\n",
       "      <th>Char_pos_series</th>\n",
       "      <th>Char_neg_series</th>\n",
       "      <th>...</th>\n",
       "      <th>fname</th>\n",
       "      <th>Attraction_mean</th>\n",
       "      <th>Attraction_series</th>\n",
       "      <th>fname</th>\n",
       "      <th>ME_series</th>\n",
       "      <th>ME_long</th>\n",
       "      <th>fname</th>\n",
       "      <th>HE_series</th>\n",
       "      <th>fname</th>\n",
       "      <th>CO_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k00300002554</th>\n",
       "      <td>k00300002554§emotions_dataset.tsv</td>\n",
       "      <td>0.027675</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>[0.5, 2.25, 0.75, 0.5, 0.25, 0.0, 0.0, 0.25, 0...</td>\n",
       "      <td>[0.25, 0.5, 2.0, 0.0, 0.25, 1.25, 0.25, 0.5, 0...</td>\n",
       "      <td>k00300002554§character_dataset.tsv</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>[0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.25...</td>\n",
       "      <td>[0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.2...</td>\n",
       "      <td>...</td>\n",
       "      <td>k00300002554§attraction_dataset.tsv</td>\n",
       "      <td>0.083595</td>\n",
       "      <td>[6.5, 1.0, 0.5, 2.25, 0.75, 0.5, 0.0, 0.5, 1.0...</td>\n",
       "      <td>k00300002554§ME.tsv</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>k00300002554§HE.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>k00300002554§CO.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k00300000050</th>\n",
       "      <td>k00300000050§emotions_dataset.tsv</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>[0.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5, 1.0, 0.0, 2.0, 6.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>k00300000050§character_dataset.tsv</td>\n",
       "      <td>0.006562</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3.5, 7.0, 1.0, 6.0, 5.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>k00300000050§attraction_dataset.tsv</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>[1.5, 2.0, 0.0, 3.0, 7.0, 0.0, 6.0, 0.0, 5.0, ...</td>\n",
       "      <td>k00300000050§ME.tsv</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>k00300000050§HE.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>k00300000050§CO.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k00300002084</th>\n",
       "      <td>k00300002084§emotions_dataset.tsv</td>\n",
       "      <td>0.022425</td>\n",
       "      <td>0.019764</td>\n",
       "      <td>[0.8571428571428571, 0.5714285714285714, 0.571...</td>\n",
       "      <td>[1.2857142857142858, 0.2857142857142857, 0.142...</td>\n",
       "      <td>k00300002084§character_dataset.tsv</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.014823</td>\n",
       "      <td>[1.2857142857142858, 0.2857142857142857, 0.285...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.7142857142857143, 0.85714285...</td>\n",
       "      <td>...</td>\n",
       "      <td>k00300002084§attraction_dataset.tsv</td>\n",
       "      <td>0.039149</td>\n",
       "      <td>[2.5714285714285716, 0.42857142857142855, 0.14...</td>\n",
       "      <td>k00300002084§ME.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>k00300002084§HE.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>k00300002084§CO.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k00300002591</th>\n",
       "      <td>k00300002591§emotions_dataset.tsv</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>0.020662</td>\n",
       "      <td>[0.5, 1.0, 0.25, 1.0, 1.75, 0.75, 1.5, 0.25, 1...</td>\n",
       "      <td>[1.75, 1.75, 0.5, 2.5, 0.5, 2.0, 2.5, 0.5, 1.0...</td>\n",
       "      <td>k00300002591§character_dataset.tsv</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>[0.5, 1.25, 0.25, 0.25, 0.75, 0.5, 1.0, 0.5, 0...</td>\n",
       "      <td>[0.0, 1.0, 0.5, 1.25, 0.5, 0.25, 0.25, 0.5, 0....</td>\n",
       "      <td>...</td>\n",
       "      <td>k00300002591§attraction_dataset.tsv</td>\n",
       "      <td>0.047269</td>\n",
       "      <td>[5.25, 3.75, 3.25, 1.25, 3.25, 3.25, 6.0, 1.0,...</td>\n",
       "      <td>k00300002591§ME.tsv</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>k00300002591§HE.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>k00300002591§CO.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783740911157</th>\n",
       "      <td>9783740911157§emotions_dataset.tsv</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.024153</td>\n",
       "      <td>[0.75, 0.75, 0.75, 1.25, 0.25, 0.75, 0.25, 0.0...</td>\n",
       "      <td>[1.0, 2.0, 1.75, 1.25, 1.75, 3.0, 0.25, 0.0, 0...</td>\n",
       "      <td>9783740911157§character_dataset.tsv</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.25, 0.0...</td>\n",
       "      <td>[0.25, 0.5, 0.5, 0.0, 0.5, 0.5, 0.25, 0.0, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>9783740911157§attraction_dataset.tsv</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>[0.0, 1.25, 1.0, 0.25, 1.75, 0.25, 0.75, 0.75,...</td>\n",
       "      <td>9783740911157§ME.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>9783740911157§HE.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9783740911157§CO.tsv</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783959792387</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9783959792387§ME.tsv</td>\n",
       "      <td>[0, nan, nan, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>1</td>\n",
       "      <td>9783959792387§HE.tsv</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9783959792387§CO.tsv</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783959790697</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9783959790697§ME.tsv</td>\n",
       "      <td>[0, nan, nan, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>1</td>\n",
       "      <td>9783959790697§HE.tsv</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9783959790697§CO.tsv</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783959793315</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9783959793315§ME.tsv</td>\n",
       "      <td>[0, nan, nan, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>1</td>\n",
       "      <td>9783959793315§HE.tsv</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9783959793315§CO.tsv</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783959791502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9783959791502§ME.tsv</td>\n",
       "      <td>[0, nan, nan, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>1</td>\n",
       "      <td>9783959791502§HE.tsv</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9783959791502§CO.tsv</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783959790338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9783959790338§ME.tsv</td>\n",
       "      <td>[0, nan, nan, nan, nan, nan, nan, nan, nan, na...</td>\n",
       "      <td>1</td>\n",
       "      <td>9783959790338§HE.tsv</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>9783959790338§CO.tsv</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            fname  Emotion_pos_mean  \\\n",
       "k00300002554    k00300002554§emotions_dataset.tsv          0.027675   \n",
       "k00300000050    k00300000050§emotions_dataset.tsv          0.017717   \n",
       "k00300002084    k00300002084§emotions_dataset.tsv          0.022425   \n",
       "k00300002591    k00300002591§emotions_dataset.tsv          0.027172   \n",
       "9783740911157  9783740911157§emotions_dataset.tsv          0.014803   \n",
       "...                                           ...               ...   \n",
       "9783959792387                                 NaN               NaN   \n",
       "9783959790697                                 NaN               NaN   \n",
       "9783959793315                                 NaN               NaN   \n",
       "9783959791502                                 NaN               NaN   \n",
       "9783959790338                                 NaN               NaN   \n",
       "\n",
       "               Emotion_neg_mean  \\\n",
       "k00300002554           0.019686   \n",
       "k00300000050           0.020997   \n",
       "k00300002084           0.019764   \n",
       "k00300002591           0.020662   \n",
       "9783740911157          0.024153   \n",
       "...                         ...   \n",
       "9783959792387               NaN   \n",
       "9783959790697               NaN   \n",
       "9783959793315               NaN   \n",
       "9783959791502               NaN   \n",
       "9783959790338               NaN   \n",
       "\n",
       "                                              Emotion_pos_series  \\\n",
       "k00300002554   [0.5, 2.25, 0.75, 0.5, 0.25, 0.0, 0.0, 0.25, 0...   \n",
       "k00300000050   [0.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "k00300002084   [0.8571428571428571, 0.5714285714285714, 0.571...   \n",
       "k00300002591   [0.5, 1.0, 0.25, 1.0, 1.75, 0.75, 1.5, 0.25, 1...   \n",
       "9783740911157  [0.75, 0.75, 0.75, 1.25, 0.25, 0.75, 0.25, 0.0...   \n",
       "...                                                          ...   \n",
       "9783959792387                                                NaN   \n",
       "9783959790697                                                NaN   \n",
       "9783959793315                                                NaN   \n",
       "9783959791502                                                NaN   \n",
       "9783959790338                                                NaN   \n",
       "\n",
       "                                              Emotion_neg_series  \\\n",
       "k00300002554   [0.25, 0.5, 2.0, 0.0, 0.25, 1.25, 0.25, 0.5, 0...   \n",
       "k00300000050   [0.5, 1.0, 0.0, 2.0, 6.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "k00300002084   [1.2857142857142858, 0.2857142857142857, 0.142...   \n",
       "k00300002591   [1.75, 1.75, 0.5, 2.5, 0.5, 2.0, 2.5, 0.5, 1.0...   \n",
       "9783740911157  [1.0, 2.0, 1.75, 1.25, 1.75, 3.0, 0.25, 0.0, 0...   \n",
       "...                                                          ...   \n",
       "9783959792387                                                NaN   \n",
       "9783959790697                                                NaN   \n",
       "9783959793315                                                NaN   \n",
       "9783959791502                                                NaN   \n",
       "9783959790338                                                NaN   \n",
       "\n",
       "                                             fname  Char_pos_mean  \\\n",
       "k00300002554    k00300002554§character_dataset.tsv       0.015692   \n",
       "k00300000050    k00300000050§character_dataset.tsv       0.006562   \n",
       "k00300002084    k00300002084§character_dataset.tsv       0.012923   \n",
       "k00300002591    k00300002591§character_dataset.tsv       0.009341   \n",
       "9783740911157  9783740911157§character_dataset.tsv       0.003896   \n",
       "...                                            ...            ...   \n",
       "9783959792387                                  NaN            NaN   \n",
       "9783959790697                                  NaN            NaN   \n",
       "9783959793315                                  NaN            NaN   \n",
       "9783959791502                                  NaN            NaN   \n",
       "9783959790338                                  NaN            NaN   \n",
       "\n",
       "               Char_neg_mean  \\\n",
       "k00300002554        0.007418   \n",
       "k00300000050        0.023622   \n",
       "k00300002084        0.014823   \n",
       "k00300002591        0.006510   \n",
       "9783740911157       0.007791   \n",
       "...                      ...   \n",
       "9783959792387            NaN   \n",
       "9783959790697            NaN   \n",
       "9783959793315            NaN   \n",
       "9783959791502            NaN   \n",
       "9783959790338            NaN   \n",
       "\n",
       "                                                 Char_pos_series  \\\n",
       "k00300002554   [0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.25...   \n",
       "k00300000050   [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, ...   \n",
       "k00300002084   [1.2857142857142858, 0.2857142857142857, 0.285...   \n",
       "k00300002591   [0.5, 1.25, 0.25, 0.25, 0.75, 0.5, 1.0, 0.5, 0...   \n",
       "9783740911157  [0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.25, 0.0...   \n",
       "...                                                          ...   \n",
       "9783959792387                                                NaN   \n",
       "9783959790697                                                NaN   \n",
       "9783959793315                                                NaN   \n",
       "9783959791502                                                NaN   \n",
       "9783959790338                                                NaN   \n",
       "\n",
       "                                                 Char_neg_series  ...  \\\n",
       "k00300002554   [0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.2...  ...   \n",
       "k00300000050   [3.5, 7.0, 1.0, 6.0, 5.0, 0.0, 0.0, 0.0, 1.0, ...  ...   \n",
       "k00300002084   [1.0, 0.0, 0.0, 0.7142857142857143, 0.85714285...  ...   \n",
       "k00300002591   [0.0, 1.0, 0.5, 1.25, 0.5, 0.25, 0.25, 0.5, 0....  ...   \n",
       "9783740911157  [0.25, 0.5, 0.5, 0.0, 0.5, 0.5, 0.25, 0.0, 0.0...  ...   \n",
       "...                                                          ...  ...   \n",
       "9783959792387                                                NaN  ...   \n",
       "9783959790697                                                NaN  ...   \n",
       "9783959793315                                                NaN  ...   \n",
       "9783959791502                                                NaN  ...   \n",
       "9783959790338                                                NaN  ...   \n",
       "\n",
       "                                              fname  Attraction_mean  \\\n",
       "k00300002554    k00300002554§attraction_dataset.tsv         0.083595   \n",
       "k00300000050    k00300000050§attraction_dataset.tsv         0.037402   \n",
       "k00300002084    k00300002084§attraction_dataset.tsv         0.039149   \n",
       "k00300002591    k00300002591§attraction_dataset.tsv         0.047269   \n",
       "9783740911157  9783740911157§attraction_dataset.tsv         0.016751   \n",
       "...                                             ...              ...   \n",
       "9783959792387                                   NaN              NaN   \n",
       "9783959790697                                   NaN              NaN   \n",
       "9783959793315                                   NaN              NaN   \n",
       "9783959791502                                   NaN              NaN   \n",
       "9783959790338                                   NaN              NaN   \n",
       "\n",
       "                                               Attraction_series  \\\n",
       "k00300002554   [6.5, 1.0, 0.5, 2.25, 0.75, 0.5, 0.0, 0.5, 1.0...   \n",
       "k00300000050   [1.5, 2.0, 0.0, 3.0, 7.0, 0.0, 6.0, 0.0, 5.0, ...   \n",
       "k00300002084   [2.5714285714285716, 0.42857142857142855, 0.14...   \n",
       "k00300002591   [5.25, 3.75, 3.25, 1.25, 3.25, 3.25, 6.0, 1.0,...   \n",
       "9783740911157  [0.0, 1.25, 1.0, 0.25, 1.75, 0.25, 0.75, 0.75,...   \n",
       "...                                                          ...   \n",
       "9783959792387                                                NaN   \n",
       "9783959790697                                                NaN   \n",
       "9783959793315                                                NaN   \n",
       "9783959791502                                                NaN   \n",
       "9783959790338                                                NaN   \n",
       "\n",
       "                              fname  \\\n",
       "k00300002554    k00300002554§ME.tsv   \n",
       "k00300000050    k00300000050§ME.tsv   \n",
       "k00300002084    k00300002084§ME.tsv   \n",
       "k00300002591    k00300002591§ME.tsv   \n",
       "9783740911157  9783740911157§ME.tsv   \n",
       "...                             ...   \n",
       "9783959792387  9783959792387§ME.tsv   \n",
       "9783959790697  9783959790697§ME.tsv   \n",
       "9783959793315  9783959793315§ME.tsv   \n",
       "9783959791502  9783959791502§ME.tsv   \n",
       "9783959790338  9783959790338§ME.tsv   \n",
       "\n",
       "                                                       ME_series ME_long  \\\n",
       "k00300002554   [0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, ...       2   \n",
       "k00300000050   [0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, ...       2   \n",
       "k00300002084   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       7   \n",
       "k00300002591   [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, ...       3   \n",
       "9783740911157  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       7   \n",
       "...                                                          ...     ...   \n",
       "9783959792387  [0, nan, nan, nan, nan, nan, nan, nan, nan, na...       1   \n",
       "9783959790697  [0, nan, nan, nan, nan, nan, nan, nan, nan, na...       1   \n",
       "9783959793315  [0, nan, nan, nan, nan, nan, nan, nan, nan, na...       1   \n",
       "9783959791502  [0, nan, nan, nan, nan, nan, nan, nan, nan, na...       1   \n",
       "9783959790338  [0, nan, nan, nan, nan, nan, nan, nan, nan, na...       1   \n",
       "\n",
       "                              fname  \\\n",
       "k00300002554    k00300002554§HE.tsv   \n",
       "k00300000050    k00300000050§HE.tsv   \n",
       "k00300002084    k00300002084§HE.tsv   \n",
       "k00300002591    k00300002591§HE.tsv   \n",
       "9783740911157  9783740911157§HE.tsv   \n",
       "...                             ...   \n",
       "9783959792387  9783959792387§HE.tsv   \n",
       "9783959790697  9783959790697§HE.tsv   \n",
       "9783959793315  9783959793315§HE.tsv   \n",
       "9783959791502  9783959791502§HE.tsv   \n",
       "9783959790338  9783959790338§HE.tsv   \n",
       "\n",
       "                                                       HE_series  \\\n",
       "k00300002554   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "k00300000050   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "k00300002084   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "k00300002591   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9783740911157  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                          ...   \n",
       "9783959792387  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9783959790697  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9783959793315  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9783959791502  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9783959790338  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                              fname  \\\n",
       "k00300002554    k00300002554§CO.tsv   \n",
       "k00300000050    k00300000050§CO.tsv   \n",
       "k00300002084    k00300002084§CO.tsv   \n",
       "k00300002591    k00300002591§CO.tsv   \n",
       "9783740911157  9783740911157§CO.tsv   \n",
       "...                             ...   \n",
       "9783959792387  9783959792387§CO.tsv   \n",
       "9783959790697  9783959790697§CO.tsv   \n",
       "9783959793315  9783959793315§CO.tsv   \n",
       "9783959791502  9783959791502§CO.tsv   \n",
       "9783959790338  9783959790338§CO.tsv   \n",
       "\n",
       "                                                       CO_series  \n",
       "k00300002554   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "k00300000050   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "k00300002084   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "k00300002591   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "9783740911157  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "...                                                          ...  \n",
       "9783959792387  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9783959790697  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9783959793315  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9783959791502  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9783959790338  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[1350 rows x 25 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d48bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigframe.to_csv(\"bigframe.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
